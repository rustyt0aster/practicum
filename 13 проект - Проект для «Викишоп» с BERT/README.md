# [Проект для «Викишоп» с BERT](https://github.com/rustyt0aster/practicum/blob/main/13%20проект%20-%20Проект%20для%20«Викишоп»%20с%20BERT/Проект%20для%20«Викишоп»%20с%20BERT.ipynb)

**Цель проекта:** Обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.

| Суть проекта | Результат | Библиотеки | Инструменты и важные детали |
| :-- | :-- |:--:|:--:|
| Обработка естественного языка. Построить модель со значением метрики качества F1 не меньше 0.75. | Задача решена двумя различными методами. BERT очень точен, но сильно зависит от аппаратных возможностей оборудования. TF-IDF менее точен, но значительно быстрее может быть обработан. | Библиотеки: pandas<br>numpy<br>matplotlib.pyplot<br><br>torch<br>transformers<br>requests<br>lightgbm<br>nltk<br>re<br>warnings<br>pywsd<br>Модули: sklearn.model_selection (train_test_split, RandomizedSearchCV);<br>модели LogisticRegression, RandomForestClassifier, lightgbm; sklearn.metrics.f1_score; train_test_split. Применяются новые модули из сторонних библиотек, вот некоторые из них: make_pipeline из sklearn.pipeline, TfidfVectorizer из sklearn.feature_extraction.text, lemmatize_sentence из pywsd.utils, word_tokenize из nltk и др. |  |

В работе была проведена оценка производительности разных моделей: BERT и TF-IDF. 

Преобразовав текст для BERT, мы получили значение метрики близкое к максимуму: единице. В то же время, модели обучались лишь на 10% данных, здесь упираемся в аппаратные ограничения и скорость обучения и перебора параметров. 
В методе TF-IDF мы добились необходимого значения метрики F1. Здесь модель обучалась уже на всем наборе данных. То есть, даже если этот метод менее точен, чем BERT, он намного менее требователен к аппаратным ресурсам и намного быстрее.
Также, точность моделей сильно зависит от предобученных моделей и дополнительных преобразований.

[Вернуться](https://github.com/rustyt0aster/practicum/tree/main#readme)
